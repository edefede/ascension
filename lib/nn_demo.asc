// ============================================================================
// NEURAL NETWORK DEMO 
// ============================================================================
// Dimostra: Neurone singolo -> Perceptron (AND) -> MLP (XOR)
// ============================================================================

include "neural_network.asc";

print("╔══════════════════════════════════════════════════════════════╗");
print("║           NEURAL NETWORK DEMO - Ascension 12.7               ║");
print("╚══════════════════════════════════════════════════════════════╝");
print("");

// ============================================================================
// DEMO 1: Singolo Neurone
// ============================================================================
print("┌────────────────────────────────────────────────────────────────┐");
print("│ DEMO 1: SINGOLO NEURONE                                        │");
print("└────────────────────────────────────────────────────────────────┘");
print("");

// Un neurone con pesi fissi che simula AND
print("Neurone configurato manualmente come AND:");
print("Pesi: w1=1, w2=1, bias=-1.5");
print("");

// Test AND con neurone
print("Input -> Output (soglia ~0.5)");
out = neuron_2in(0, 0, 1, 1, -1.5);
print("  0 AND 0 =", out);

out = neuron_2in(0, 1, 1, 1, -1.5);
print("  0 AND 1 =", out);

out = neuron_2in(1, 0, 1, 1, -1.5);
print("  1 AND 0 =", out);

out = neuron_2in(1, 1, 1, 1, -1.5);
print("  1 AND 1 =", out);

print("");

// ============================================================================
// DEMO 2: Perceptron Training (AND gate)
// ============================================================================
print("┌────────────────────────────────────────────────────────────────┐");
print("│ DEMO 2: PERCEPTRON TRAINING (AND gate)                         │");
print("└────────────────────────────────────────────────────────────────┘");
print("");

// Dataset AND
// Input: (0,0)=0, (0,1)=0, (1,0)=0, (1,1)=1
and_x1[0] = 0; and_x2[0] = 0; and_y[0] = 0;
and_x1[1] = 0; and_x2[1] = 1; and_y[1] = 0;
and_x1[2] = 1; and_x2[2] = 0; and_y[2] = 0;
and_x1[3] = 1; and_x2[3] = 1; and_y[3] = 1;

// Inizializza pesi random
p_w1 = random_weight();
p_w2 = random_weight();
p_bias = random_weight();

print("Pesi iniziali:");
print("  w1=", p_w1, "w2=", p_w2, "bias=", p_bias);
print("");

// Training
lr = 0.1;
epochs = 100;

print("Training per", epochs, "epoche...");

for (epoch = 0; epoch < epochs; epoch += 1) {
    total_error = 0;
    
    for (i = 0; i < 4; i += 1) {
        err = perceptron_train_step(and_x1[i], and_x2[i], and_y[i], lr);
        total_error = total_error + err;
    }
    
    // Stampa ogni 20 epoche
    if (epoch % 20 == 0) {
        print("  Epoca", epoch, "- Errori:", total_error);
    }
}

print("");
print("Pesi finali:");
print("  w1=", p_w1, "w2=", p_w2, "bias=", p_bias);
print("");

// Test
print("Test AND dopo training:");
print("  0 AND 0 =", perceptron_predict(0, 0));
print("  0 AND 1 =", perceptron_predict(0, 1));
print("  1 AND 0 =", perceptron_predict(1, 0));
print("  1 AND 1 =", perceptron_predict(1, 1));
print("");

// ============================================================================
// DEMO 3: Perceptron per OR
// ============================================================================
print("┌────────────────────────────────────────────────────────────────┐");
print("│ DEMO 3: PERCEPTRON TRAINING (OR gate)                          │");
print("└────────────────────────────────────────────────────────────────┘");
print("");

// Dataset OR
or_x1[0] = 0; or_x2[0] = 0; or_y[0] = 0;
or_x1[1] = 0; or_x2[1] = 1; or_y[1] = 1;
or_x1[2] = 1; or_x2[2] = 0; or_y[2] = 1;
or_x1[3] = 1; or_x2[3] = 1; or_y[3] = 1;

// Reset pesi
p_w1 = random_weight();
p_w2 = random_weight();
p_bias = random_weight();

print("Training OR...");

for (epoch = 0; epoch < epochs; epoch += 1) {
    for (i = 0; i < 4; i += 1) {
        perceptron_train_step(or_x1[i], or_x2[i], or_y[i], lr);
    }
}

print("Test OR dopo training:");
print("  0 OR 0 =", perceptron_predict(0, 0));
print("  0 OR 1 =", perceptron_predict(0, 1));
print("  1 OR 0 =", perceptron_predict(1, 0));
print("  1 OR 1 =", perceptron_predict(1, 1));
print("");

// ============================================================================
// DEMO 4: MLP per XOR (la sfida!)
// ============================================================================
print("┌────────────────────────────────────────────────────────────────┐");
print("│ DEMO 4: MLP TRAINING (XOR gate) - La sfida classica!           │");
print("└────────────────────────────────────────────────────────────────┘");
print("");

// Dataset XOR
xor_x1[0] = 0; xor_x2[0] = 0; xor_y[0] = 0;
xor_x1[1] = 0; xor_x2[1] = 1; xor_y[1] = 1;
xor_x1[2] = 1; xor_x2[2] = 0; xor_y[2] = 1;
xor_x1[3] = 1; xor_x2[3] = 1; xor_y[3] = 0;

// Inizializza MLP
print("Inizializzazione rete 2-2-1...");
mlp_init();
mlp_print_weights();
print("");

// Training XOR
xor_lr = 2.0;
xor_epochs = 20000;

print("Training XOR per", xor_epochs, "epoche (lr=", xor_lr, ")...");
print("");

for (epoch = 0; epoch < xor_epochs; epoch += 1) {
    total_mse = 0;
    
    for (i = 0; i < 4; i += 1) {
        mse = mlp_train_step(xor_x1[i], xor_x2[i], xor_y[i], xor_lr);
        total_mse = total_mse + mse;
    }
    
    // Stampa progresso
    if (epoch % 4000 == 0) {
        avg_mse = total_mse / 4;
        print("  Epoca", epoch, "- MSE medio:", avg_mse);
    }
}

print("");
print("Training completato!");
print("");

mlp_print_weights();
print("");

// Test XOR
print("┌────────────────────────────────────────────────────────────────┐");
print("│ RISULTATI XOR                                                  │");
print("└────────────────────────────────────────────────────────────────┘");
print("");

print("Input -> Output Raw -> Output Binario (soglia 0.5)");
print("");

out0 = mlp_predict(0, 0);
bin0 = mlp_predict_binary(0, 0);
print("  0 XOR 0 =", out0, "->", bin0, "(atteso: 0)");

out1 = mlp_predict(0, 1);
bin1 = mlp_predict_binary(0, 1);
print("  0 XOR 1 =", out1, "->", bin1, "(atteso: 1)");

out2 = mlp_predict(1, 0);
bin2 = mlp_predict_binary(1, 0);
print("  1 XOR 0 =", out2, "->", bin2, "(atteso: 1)");

out3 = mlp_predict(1, 1);
bin3 = mlp_predict_binary(1, 1);
print("  1 XOR 1 =", out3, "->", bin3, "(atteso: 0)");

print("");

// Verifica successo
success = 0;
if (bin0 == 0) { success = success + 1; }
if (bin1 == 1) { success = success + 1; }
if (bin2 == 1) { success = success + 1; }
if (bin3 == 0) { success = success + 1; }

print("╔══════════════════════════════════════════════════════════════╗");
if (success == 4) {
    print("║  ✓ XOR RISOLTO! 4/4 corretti - La rete ha imparato!         ║");
} else {
    print("║  Risultato:", success, "/4 corretti                              ║");
    print("║  (Prova a rieseguire - i pesi iniziali sono casuali)        ║");
}
print("╚══════════════════════════════════════════════════════════════╝");
